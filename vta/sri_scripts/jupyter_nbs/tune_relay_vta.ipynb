{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TARGET': 'zcu104', 'HW_VER': '0.0.1'}\n",
      "{'LOG_INP_WIDTH': 3, 'LOG_WGT_WIDTH': 3, 'LOG_ACC_WIDTH': 5, 'LOG_BATCH': 0, 'LOG_BLOCK_IN': 4, 'LOG_BLOCK_OUT': 4, 'LOG_UOP_WIDTH': 5, 'LOG_UOP_BUFF_SIZE': 15, 'LOG_INP_BUFF_SIZE': 15, 'LOG_WGT_BUFF_SIZE': 18, 'LOG_ACC_BUFF_SIZE': 17, 'LOG_INP_FACTOR_RESTRICT': 0, 'LOG_WGT_FACTOR_RESTRICT': 0, 'LOG_ACC_FACTOR_RESTRICT': 0, 'SHL_MEM_AXI_DATA_BITS': 64, 'SHL_VME_CLT_TAG_BITS': 19, 'DPI_LEN_BITS': 8, 'DPI_ADDR_BITS': 64, 'DPI_DATA_BITS': 64, 'DPI_TAG_BITS': 8, 'DPI_DELAY': 16, 'ENABLE_INSTRUCTION_CLP': 1, 'ENABLE_RUNTIME_GREEDY_UOP_LOADS': 1, 'ENABLE_RUNTIME_VALUE_BASED_UOP_CONSOLIDATION': 1, 'TARGET': 'zcu104', 'HW_VER': '0.0.1', 'ENABLE_VTHREAD': 1, 'VTHREAD_NAME': 'dthread'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srchand/anaconda3/envs/tvm-build-il-2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from tvm import topi\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, utils, download\n",
    "from tvm.autotvm.measure.measure_methods import request_remote\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_network_pytorch(env, target, model, start_pack, start_pack_idx, stop_pack, stop_pack_idx):\n",
    "    \n",
    "    input_name = \"input0\"\n",
    "    \n",
    "    # Populate the shape and data type dictionary\n",
    "    dtype_dict = {\"data\": \"float32\"}\n",
    "    shape_dict = {\"data\": (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "    # Get off the shelf gluon model, and convert to relay\n",
    "    pytorch_model = torch.hub.load('pytorch/vision', model, pretrained=True)\n",
    "    input_shape = [1, 3, 224, 224]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    scripted_model = torch.jit.trace(pytorch_model, input_data).eval()\n",
    "    \n",
    "    shape_list = [(input_name, input_shape)]\n",
    "    mod , params = relay.frontend.from_pytorch(scripted_model, shape_list)    \n",
    "\n",
    "    # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "\n",
    "    # Perform quantization in Relay\n",
    "    # Note: We set opt_level to 3 in order to fold batch norm\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "            mod = relay.quantize.quantize(mod, params=params)\n",
    "\n",
    "    # Perform graph packing and constant folding for VTA target\n",
    "    if target.device_name == \"vta\":\n",
    "        assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "        relay_prog = graph_pack(\n",
    "            mod[\"main\"],\n",
    "            env.BATCH,\n",
    "            env.BLOCK_IN,\n",
    "            env.BLOCK_OUT,\n",
    "            env.WGT_WIDTH,\n",
    "            start_name=start_pack,\n",
    "            start_name_idx=start_pack_idx,\n",
    "            stop_name=stop_pack,\n",
    "            stop_name_idx=stop_pack_idx,\n",
    "        )\n",
    "\n",
    "    return relay_prog, params\n",
    "\n",
    "\n",
    "def compile_network_mxnet(env, target, model, start_pack, start_pack_idx, stop_pack, stop_pack_idx):\n",
    "        \n",
    "    # Populate the shape and data type dictionary\n",
    "    dtype_dict = {\"data\": \"float32\"}\n",
    "    shape_dict = {\"data\": (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "    # Get off the shelf gluon model, and convert to relay\n",
    "    gluon_model = vision.get_model(model, pretrained=True)\n",
    "    mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "    \n",
    "\n",
    "    # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n",
    "\n",
    "    # Perform quantization in Relay\n",
    "    # Note: We set opt_level to 3 in order to fold batch norm\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "            mod = relay.quantize.quantize(mod, params=params)\n",
    "\n",
    "    # Perform graph packing and constant folding for VTA target\n",
    "    if target.device_name == \"vta\":\n",
    "        assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "        relay_prog = graph_pack(\n",
    "            mod[\"main\"],\n",
    "            env.BATCH,\n",
    "            env.BLOCK_IN,\n",
    "            env.BLOCK_OUT,\n",
    "            env.WGT_WIDTH,\n",
    "            start_name=start_pack,\n",
    "            start_name_idx=start_pack_idx,\n",
    "            stop_name=stop_pack,\n",
    "            stop_name_idx=stop_pack_idx,\n",
    "        )\n",
    "\n",
    "    return relay_prog, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_name = \"input0\"\n",
    "    \n",
    "    # Populate the shape and data type dictionary\n",
    "dtype_dict = {\"data\": \"float32\"}\n",
    "shape_dict = {\"data\": (1, 3, 224, 224)}\n",
    "\n",
    "# Get off the shelf gluon model, and convert to relay\n",
    "gluon_model = vision.get_model(\"mobilenetv2_1.0\", pretrained=True)\n",
    "# pytorch_model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\n",
    "\n",
    "input_shape = [1, 3, 224, 224]\n",
    "# input_data = torch.randn(input_shape)\n",
    "# scripted_model = torch.jit.trace(pytorch_model, input_data).eval()\n",
    "\n",
    "# shape_list = [(input_name, input_shape)]\n",
    "mod , params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "        with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "            mod = relay.quantize.quantize(mod, params=params)\n",
    "            \n",
    "print(mod.astext(show_meta_data=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start RPC Tracker\n",
    "TVM uses an RPC session to communicate with Pynq boards.\n",
    "During tuning, the tuner will send the generated code to the board and\n",
    "measure the speed of code on the board.\n",
    "\n",
    "To scale up tuning, TVM uses an RPC Tracker to manage multiple devices.\n",
    "The RPC Tracker is a centralized controller node. We can register all devices to\n",
    "the tracker. For example, if we have 10 Pynq boards, we can register all of them\n",
    "to the tracker, and run 10 measurements in parallel, accelerating the tuning process.\n",
    "\n",
    "To start an RPC tracker, run this command on the host machine. The tracker is\n",
    "required during the whole tuning process, so we need to open a new terminal for\n",
    "this command:\n",
    "\n",
    "```bash\n",
    "python -m tvm.exec.rpc_tracker --host=0.0.0.0 --port=9190\n",
    "```\n",
    "The expected output is:\n",
    "\n",
    "```bash\n",
    "INFO:RPCTracker:bind to 0.0.0.0:9190\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register devices to RPC Tracker\n",
    "Now we can register our devices to the tracker. The first step is to\n",
    "build the TVM runtime for the Pynq devices.\n",
    "\n",
    "Follow `vta-index`\n",
    "to build the TVM runtime on the device. Then register the device to the tracker with:\n",
    "\n",
    "```bash\n",
    "python -m tvm.exec.rpc_server --tracker=[HOST_IP]:9190 --key=pynq\n",
    "```\n",
    "(replace :code:`[HOST_IP]` with the IP address of your host machine)\n",
    "\n",
    "After registering devices, we can confirm it by querying the rpc_tracker:\n",
    "\n",
    "```bash\n",
    "python -m tvm.exec.query_rpc_tracker --host=0.0.0.0 --port=9190\n",
    "```\n",
    "For example, if we have 6 Pynq boards and 11 Raspberry Pi 3B,\n",
    "the output can be\n",
    "\n",
    "```bash\n",
    "Queue Status\n",
    "----------------------------------\n",
    "key          total  free  pending\n",
    "----------------------------------\n",
    "pynq         6      6     0\n",
    "rpi3b        11     11    0\n",
    "----------------------------------\n",
    "```\n",
    "You can register multiple devices to the tracker to accelerate tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Tuning Options\n",
    "Before tuning, we should apply some configurations.\n",
    "Here we use an Pynq-Z1 board as an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracker host and port can be set by your environment\n",
    "tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", \"127.0.0.1\")\n",
    "tracker_port = int(os.environ.get(\"TVM_TRACKER_PORT\", 9190))\n",
    "\n",
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# This target is used for cross compilation. You can query it by :code:`gcc -v` on your device.\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The ``start_pack`` and ``stop_pack`` labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "network = \"mobilenetv2_1.0\"\n",
    "start_pack = \"cast\"\n",
    "start_pack_idx=7\n",
    "stop_pack = \"nn.global_avg_pool2d\"\n",
    "stop_pack_idx = 558\n",
    "\n",
    "# Tuning option\n",
    "log_file = \"%s.%s.log\" % (device, network)\n",
    "tuning_option = {\n",
    "    \"log_filename\": log_file,\n",
    "    \"tuner\": \"random\",\n",
    "    \"n_trial\": 1000,\n",
    "    \"early_stopping\": None,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(),\n",
    "        runner=autotvm.RPCRunner(\n",
    "            env.TARGET,\n",
    "            host=tracker_host,\n",
    "            port=tracker_port,\n",
    "            number=5,\n",
    "            timeout=60,\n",
    "#             module_loader=vta.module_loader(),\n",
    "            # check_correctness=True, # TODO: re-enable when check_correctness works again.\n",
    "        ),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can skip the implementation of this function for this tutorial.\n",
    "def tune_tasks(\n",
    "    tasks,\n",
    "    measure_option,\n",
    "    tuner=\"xgb\",\n",
    "    n_trial=1000,\n",
    "    early_stopping=None,\n",
    "    log_filename=\"tuning.log\",\n",
    "    use_transfer_learning=True,\n",
    "):\n",
    "\n",
    "    # create tmp log file\n",
    "    tmp_log_file = log_filename + \".tmp\"\n",
    "    if os.path.exists(tmp_log_file):\n",
    "        os.remove(tmp_log_file)\n",
    "\n",
    "    for i, tsk in enumerate(reversed(tasks)):\n",
    "        prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "\n",
    "        # create tuner\n",
    "        if tuner == \"xgb\" or tuner == \"xgb-rank\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\")\n",
    "        elif tuner == \"xgb_knob\":\n",
    "            tuner_obj = XGBTuner(tsk, loss_type=\"rank\", feature_type=\"knob\")\n",
    "        elif tuner == \"ga\":\n",
    "            tuner_obj = GATuner(tsk, pop_size=50)\n",
    "        elif tuner == \"random\":\n",
    "            tuner_obj = RandomTuner(tsk)\n",
    "        elif tuner == \"gridsearch\":\n",
    "            tuner_obj = GridSearchTuner(tsk)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tuner: \" + tuner)\n",
    "\n",
    "        if use_transfer_learning:\n",
    "            if os.path.isfile(tmp_log_file):\n",
    "                tuner_obj.load_history(autotvm.record.load_from_file(tmp_log_file))\n",
    "\n",
    "        # do tuning\n",
    "        tsk_trial = min(n_trial, len(tsk.config_space))\n",
    "        tuner_obj.tune(\n",
    "            n_trial=tsk_trial,\n",
    "            early_stopping=early_stopping,\n",
    "            measure_option=measure_option,\n",
    "            callbacks=[\n",
    "                autotvm.callback.progress_bar(tsk_trial, prefix=prefix),\n",
    "                autotvm.callback.log_to_file(tmp_log_file),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    # pick best records to a cache file\n",
    "    autotvm.record.pick_best(tmp_log_file, log_filename)\n",
    "    os.remove(tmp_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_vta_tuning_tasks():\n",
    "    from tvm.autotvm.task import TaskExtractEnv\n",
    "\n",
    "    @tvm.te.tag_scope(tag=topi.tag.ELEMWISE)\n",
    "    def my_clip(x, a_min, a_max):\n",
    "        \"\"\"Unlike topi's current clip, put min and max into two stages.\"\"\"\n",
    "        const_min = tvm.tir.const(a_min, x.dtype)\n",
    "        const_max = tvm.tir.const(a_max, x.dtype)\n",
    "        x = te.compute(x.shape, lambda *i: tvm.te.min(x(*i), const_max), name=\"clipA\")\n",
    "        x = te.compute(x.shape, lambda *i: tvm.te.max(x(*i), const_min), name=\"clipB\")\n",
    "        return x\n",
    "\n",
    "    # init autotvm env to register VTA operator\n",
    "    TaskExtractEnv()\n",
    "\n",
    "    @autotvm.template(\"conv2d_packed.vta\")\n",
    "    def _topi_nn_conv2d(*args, **kwargs):\n",
    "        assert not kwargs, \"Do not support kwargs in template function call\"\n",
    "        A, W = args[:2]\n",
    "\n",
    "        with tvm.target.vta():\n",
    "            res = vta.top.conv2d_packed(*args, **kwargs)\n",
    "            res = topi.right_shift(res, 8)\n",
    "            res = my_clip(res, 0, 127)\n",
    "            res = topi.cast(res, \"int8\")\n",
    "\n",
    "        if tvm.target.Target.current().device_name == \"vta\":\n",
    "            s = vta.top.schedule_conv2d_packed([res])\n",
    "        else:\n",
    "            s = te.create_schedule([res.op])\n",
    "        return s, [A, W, res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract tasks...\n",
      "30\n",
      "Extracted 30 conv2d tasks:\n",
      "(1, 7, 7, 320, 1280, 1, 1, 0, 0, 1, 1)\n",
      "(1, 7, 7, 960, 320, 1, 1, 0, 0, 1, 1)\n",
      "(1, 7, 7, 960, 960, 3, 3, 1, 1, 1, 1)\n",
      "(1, 7, 7, 160, 960, 1, 1, 0, 0, 1, 1)\n",
      "(1, 7, 7, 960, 160, 1, 1, 0, 0, 1, 1)\n",
      "(1, 7, 7, 576, 160, 1, 1, 0, 0, 1, 1)\n",
      "(1, 14, 14, 576, 576, 3, 3, 1, 1, 2, 2)\n",
      "(1, 14, 14, 96, 576, 1, 1, 0, 0, 1, 1)\n",
      "(1, 14, 14, 576, 96, 1, 1, 0, 0, 1, 1)\n",
      "(1, 14, 14, 576, 576, 3, 3, 1, 1, 1, 1)\n",
      "(1, 14, 14, 384, 96, 1, 1, 0, 0, 1, 1)\n",
      "(1, 14, 14, 384, 384, 3, 3, 1, 1, 1, 1)\n",
      "(1, 14, 14, 64, 384, 1, 1, 0, 0, 1, 1)\n",
      "(1, 14, 14, 384, 64, 1, 1, 0, 0, 1, 1)\n",
      "(1, 14, 14, 192, 64, 1, 1, 0, 0, 1, 1)\n",
      "(1, 28, 28, 192, 192, 3, 3, 1, 1, 2, 2)\n",
      "(1, 28, 28, 32, 192, 1, 1, 0, 0, 1, 1)\n",
      "(1, 28, 28, 192, 32, 1, 1, 0, 0, 1, 1)\n",
      "(1, 28, 28, 192, 192, 3, 3, 1, 1, 1, 1)\n",
      "(1, 28, 28, 144, 32, 1, 1, 0, 0, 1, 1)\n",
      "(1, 56, 56, 144, 144, 3, 3, 1, 1, 2, 2)\n",
      "(1, 56, 56, 32, 144, 1, 1, 0, 0, 1, 1)\n",
      "(1, 56, 56, 144, 32, 1, 1, 0, 0, 1, 1)\n",
      "(1, 56, 56, 144, 144, 3, 3, 1, 1, 1, 1)\n",
      "(1, 56, 56, 96, 32, 1, 1, 0, 0, 1, 1)\n",
      "(1, 112, 112, 96, 96, 3, 3, 1, 1, 2, 2)\n",
      "(1, 112, 112, 16, 96, 1, 1, 0, 0, 1, 1)\n",
      "(1, 112, 112, 32, 16, 1, 1, 0, 0, 1, 1)\n",
      "(1, 112, 112, 32, 32, 3, 3, 1, 1, 1, 1)\n",
      "(1, 112, 112, 32, 32, 1, 1, 0, 0, 1, 1)\n",
      "Tuning...\n",
      "[Task  1/30]  Current/Best:    0.00/   8.18 GFLOPS | Progress: (78/1000) | 5299.84 s"
     ]
    }
   ],
   "source": [
    "def tune_and_evaluate(tuning_opt):\n",
    "\n",
    "    # Register VTA tuning tasks\n",
    "    register_vta_tuning_tasks()\n",
    "\n",
    "    # Perform task extraction on Relay program\n",
    "    print(\"Extract tasks...\")\n",
    "    relay_prog, params = compile_network_mxnet(env, target, network, start_pack, start_pack_idx, stop_pack, stop_pack_idx)\n",
    "    mod = tvm.IRModule.from_expr(relay_prog)\n",
    "    tasks = autotvm.task.extract_from_program(\n",
    "        mod,\n",
    "        params=params,\n",
    "        ops=(relay.op.get(\"nn.conv2d\"),),\n",
    "        target=target,\n",
    "        target_host=env.target_host,\n",
    "    )\n",
    "\n",
    "    # filter out non-packed conv2d task\n",
    "    tasks = list(filter(lambda t: len(t.args[0][1]) > 4 and \"conv\" in t.name, tasks))\n",
    "\n",
    "    print(len(tasks))\n",
    "    # We should have extracted 10 convolution tasks\n",
    "    assert len(tasks) == 30\n",
    "    print(\"Extracted {} conv2d tasks:\".format(len(tasks)))\n",
    "    for tsk in tasks:\n",
    "        inp = tsk.args[0][1]\n",
    "        wgt = tsk.args[1][1]\n",
    "        batch = inp[0] * inp[4]\n",
    "        in_filter = inp[1] * inp[5]\n",
    "        out_filter = wgt[0] * wgt[4]\n",
    "        height, width = inp[2], inp[3]\n",
    "        hkernel, wkernel = wgt[2], wgt[3]\n",
    "        hstride, wstride = tsk.args[2][0], tsk.args[2][1]\n",
    "        hpad, wpad = tsk.args[3][0], tsk.args[3][1]\n",
    "        print(\n",
    "            \"({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})\".format(\n",
    "                batch,\n",
    "                height,\n",
    "                width,\n",
    "                in_filter,\n",
    "                out_filter,\n",
    "                hkernel,\n",
    "                wkernel,\n",
    "                hpad,\n",
    "                wpad,\n",
    "                hstride,\n",
    "                wstride,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # We do not run the tuning in our webpage server since it takes too long.\n",
    "    # Comment the following line to run it by yourself.\n",
    "    #return\n",
    "\n",
    "    # run tuning tasks\n",
    "    print(\"Tuning...\")\n",
    "    tune_tasks(tasks, **tuning_opt)\n",
    "    \n",
    "    \n",
    "    #device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "    #device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    \n",
    "    # evaluate with tuning history\n",
    "    if env.TARGET != \"sim\":\n",
    "        # Get remote from fleet node\n",
    "        remote = autotvm.measure.request_remote(\n",
    "           env.TARGET, tracker_host, tracker_port, timeout=10000\n",
    "        )\n",
    "        #remote = rpc.connect(device_host, int(device_port))\n",
    "        # Reconfigure the JIT runtime and FPGA.\n",
    "        vta.reconfig_runtime(remote)\n",
    "        vta.program_fpga(remote, bitstream=None)\n",
    "    else:\n",
    "        # In simulation mode, host the RPC server locally.\n",
    "        remote = rpc.LocalSession()\n",
    "\n",
    "    # compile kernels with history best records\n",
    "    with autotvm.tophub.context(target, extra_files=[log_file]):\n",
    "        # Compile network\n",
    "        print(\"Compile...\")\n",
    "        if target.device_name != \"vta\":\n",
    "            with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "                lib = relay.build(\n",
    "                    relay_prog, target=target, params=params, target_host=env.target_host\n",
    "                )\n",
    "        else:\n",
    "            with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "                graph, lib, params = relay.build(\n",
    "                    relay_prog, target=target, params=params, target_host=env.target_host\n",
    "                )\n",
    "\n",
    "        # Export library\n",
    "        print(\"Upload...\")\n",
    "        temp = utils.tempdir()\n",
    "        lib.export_library(temp.relpath(\"graphlib.tar\"))\n",
    "        remote.upload(temp.relpath(\"graphlib.tar\"))\n",
    "        lib = remote.load_module(\"graphlib.tar\")\n",
    "\n",
    "        # Generate the graph executor\n",
    "        ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)\n",
    "#         m = graph_executo.GraphModule(lib[\"default\"](ctx))\n",
    "        m = graph_runtime.create(graph, lib, ctx)\n",
    "\n",
    "        # upload parameters to device\n",
    "        image = tvm.nd.array((np.random.uniform(size=(1, 3, 299, 299))).astype(\"float32\"))\n",
    "        m.set_input(\"data\", image)\n",
    "\n",
    "        # evaluate\n",
    "        print(\"Evaluate inference time cost...\")\n",
    "        timer = m.module.time_evaluator(\"run\", ctx, number=1, repeat=10)\n",
    "        tcost = timer()\n",
    "        prof_res = np.array(tcost.results) * 1000  # convert to millisecond\n",
    "        print(\n",
    "            \"Mean inference time (std dev): %.2f ms (%.2f ms)\"\n",
    "            % (np.mean(prof_res), np.std(prof_res))\n",
    "        )\n",
    "\n",
    "\n",
    "# Run the tuning and evaluate the results\n",
    "tune_and_evaluate(tuning_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tvm-build-il-2] *",
   "language": "python",
   "name": "conda-env-tvm-build-il-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
