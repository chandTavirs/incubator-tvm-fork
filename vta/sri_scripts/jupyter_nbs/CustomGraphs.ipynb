{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, sys, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "#from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, utils, download\n",
    "from tvm.relay import transform\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.runtime.enabled(\"rpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Dictionary lookup for when to start/end bit packing\n",
    "pack_dict = {\n",
    "    #\"resnet18_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet50\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet101\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"vgg16\":    [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet34_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet50_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet101_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "}\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The ``start_pack`` and ``stop_pack`` labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "#model = \"resnet18_v1\"\n",
    "#assert model in pack_dict\n",
    "model = \"resnet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = None\n",
    "if env.TARGET not in [\"sim\", \"tsim\", \"intelfocl\"]:\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = os.environ.get(\"TVM_TRACKER_PORT\", None)\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "    #device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "    device_host = \"192.168.2.99\"\n",
    "#     device_host=\"10.100.83.40\"\n",
    "\n",
    "    device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, int(device_port))\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(\n",
    "            env.TARGET, tracker_host, int(tracker_port), timeout=10000\n",
    "        )\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/overlays/vta_il/vta_apm_maxigp0_wrapper.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=None)\n",
    "#     vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_wrapper.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_axi_sniffer_uart_fifo_thres_100.bit\")\n",
    "\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "    if env.TARGET in [\"intelfocl\"]:\n",
    "        # program intelfocl aocx\n",
    "        vta.program_fpga(remote, bitstream=\"vta.bitstream\")\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Residual(nn.Module):  #@save\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                           kernel_size=3, padding=1, stride=strides)\n",
    "        #self.conv2 = None\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                          kernel_size=3, padding=1)\n",
    "            \n",
    "            \n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        Y = self.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        \n",
    "        \n",
    "        if self.conv3:\n",
    "           X = self.conv3(X)\n",
    "        \n",
    "        Y += X \n",
    "        \n",
    "        \n",
    "        return self.relu(Y)\n",
    "    \n",
    "    \n",
    "b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2,\n",
    "                                ))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "#b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True, batch_norm=False, use_relu=True))\n",
    "#b2_max_pool = nn.Sequential(*resnet_block(64, 64, 10, first_block=True, batch_norm=True, use_relu=True))\n",
    "\n",
    "#b2 = nn.Sequential(nn.Conv2d(64,128,kernel_size=3,padding=1,stride=2),nn.Conv2d(128,128,kernel_size=3,padding=1,stride=1))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "# b6 = nn.Sequential(*resnet_block(16,32,1))\n",
    "# b7 = nn.Sequential(*resnet_block(32,96,1))\n",
    "\n",
    "\"\"\"\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5,\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 1000))\n",
    "\"\"\"\n",
    "net1 = nn.Sequential(b1,b2,b3,b4,b5,nn.AdaptiveAvgPool2d((1,1)))\n",
    "# net2 = nn.Sequential(b1,b2,b3,nn.AdaptiveAvgPool2d((1,1)))\n",
    "# net3 = nn.Sequential(b1,b2,b3,b4,nn.AdaptiveAvgPool2d((1,1)))\n",
    "# net4 = nn.Sequential(b1,b2,b3,b4,b5,nn.AdaptiveAvgPool2d((1,1)))\n",
    "# net1 = nn.Sequential(b1,b5,nn.AdaptiveAvgPool2d((1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "schedule_log_files = glob.glob(r'../logs/tuning_logs/*.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-configured AutoTVM schedules\n",
    "with autotvm.tophub.context(target, extra_files=schedule_log_files):\n",
    "    \n",
    "    input_name = \"input0\"\n",
    "\n",
    "    # Populate the shape and data type dictionary for ImageNet classifier input\n",
    "    dtype_dict = {input_name: \"float32\"}\n",
    "    shape_dict = {input_name: (env.BATCH, 3, 224, 224)}\n",
    "\n",
    "\n",
    "    # Get off the shelf gluon model, and convert to relay\n",
    "    #gluon_model = vision.get_model(model, pretrained=True)\n",
    "    \n",
    "    \n",
    "    #pytorch_model = getattr(torchvision.models, model)(pretrained=True)\n",
    "    #pytorch_model = net2\n",
    "    \n",
    "    input_shape = [1, 3, 224, 224]\n",
    "    input_data = torch.randn(input_shape)\n",
    "    #scripted_model1 = torch.jit.trace(pytorch_model, input_data).eval()\n",
    "        \n",
    "    scripted_model1 = torch.jit.trace(net1, input_data).eval()\n",
    "#     scripted_model2 = torch.jit.trace(net2, input_data).eval()\n",
    "#     scripted_model3 = torch.jit.trace(net3, input_data).eval()\n",
    "#     scripted_model4 = torch.jit.trace(net4, input_data).eval()\n",
    "    \n",
    "    #net(mx.nd.array(input_data.numpy()))\n",
    "\n",
    "    \n",
    "    shape_list = [(input_name, input_shape)]\n",
    "\n",
    "\n",
    "    # Measure build start time\n",
    "    build_start = time.time()\n",
    "\n",
    "    # Start front end compilation\n",
    "    #mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    mod1, params1 = relay.frontend.from_pytorch(scripted_model1, shape_list)\n",
    "#     mod2, params2 = relay.frontend.from_pytorch(scripted_model2, shape_list)\n",
    "#     mod3, params3 = relay.frontend.from_pytorch(scripted_model3, shape_list)\n",
    "#     mod4, params4 = relay.frontend.from_pytorch(scripted_model4, shape_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n",
    "\n",
    "    #mod, params = relay.frontend.from_mxnet(net, shape_dict)\n",
    "    \n",
    "    # Update shape and type dictionary\n",
    "    shape_dict.update({k: v.shape for k, v in params1.items()})\n",
    "    dtype_dict.update({k: str(v.dtype) for k, v in params1.items()})\n",
    "\n",
    "    if target.device_name == \"vta\":\n",
    "        # Perform quantization in Relay\n",
    "        # Note: We set opt_level to 3 in order to fold batch norm\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "                mod1 = relay.quantize.quantize(mod1, params=params1)\n",
    "                #print(mod1.astext(show_meta_data=False))\n",
    "                #print(apput)\n",
    "#                 mod2 = relay.quantize.quantize(mod2, params=params2)\n",
    "#                 mod3 = relay.quantize.quantize(mod3, params=params3)\n",
    "#                 mod4 = relay.quantize.quantize(mod4, params=params4)\n",
    "                \n",
    "                \n",
    "                \n",
    "            # Perform graph packing and constant folding for VTA target\n",
    "            assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "            # do device annotation if target is intelfocl or sim\n",
    "            relay_prog1 = graph_pack(\n",
    "                mod1[\"main\"],\n",
    "                env.BATCH,\n",
    "                env.BLOCK_IN,\n",
    "                env.BLOCK_OUT,\n",
    "                env.WGT_WIDTH,\n",
    "                start_name=pack_dict[model][0],\n",
    "                stop_name=pack_dict[model][1],\n",
    "                #start_name='nn.max_pool2d',\n",
    "                device_annot=(env.TARGET == \"intelfocl\"),\n",
    "            )\n",
    "            \n",
    "#             relay_prog2 = graph_pack(\n",
    "#                 mod2[\"main\"],\n",
    "#                 env.BATCH,\n",
    "#                 env.BLOCK_IN,\n",
    "#                 env.BLOCK_OUT,\n",
    "#                 env.WGT_WIDTH,\n",
    "#                 start_name=pack_dict[model][0],\n",
    "#                 stop_name=pack_dict[model][1],\n",
    "#                 #start_name='nn.max_pool2d',\n",
    "#                 #stop_name='nn.adaptive_avg_pool2d',\n",
    "#                 device_annot=(env.TARGET == \"intelfocl\"),\n",
    "#             )\n",
    "#             relay_prog3 = graph_pack(\n",
    "#                 mod3[\"main\"],\n",
    "#                 env.BATCH,\n",
    "#                 env.BLOCK_IN,\n",
    "#                 env.BLOCK_OUT,\n",
    "#                 env.WGT_WIDTH,\n",
    "#                 start_name=pack_dict[model][0],\n",
    "#                 stop_name=pack_dict[model][1],\n",
    "#                 #start_name='nn.max_pool2d',\n",
    "#                 #stop_name='nn.adaptive_avg_pool2d',\n",
    "#                 device_annot=(env.TARGET == \"intelfocl\"),\n",
    "#             )\n",
    "#             relay_prog4 = graph_pack(\n",
    "#                 mod4[\"main\"],\n",
    "#                 env.BATCH,\n",
    "#                 env.BLOCK_IN,\n",
    "#                 env.BLOCK_OUT,\n",
    "#                 env.WGT_WIDTH,\n",
    "#                 start_name=pack_dict[model][0],\n",
    "#                 stop_name=pack_dict[model][1],\n",
    "#                 #start_name='nn.max_pool2d',\n",
    "#                 #stop_name='nn.adaptive_avg_pool2d',\n",
    "#                 device_annot=(env.TARGET == \"intelfocl\"),\n",
    "#             )\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        relay_prog = mod1[\"main\"]\n",
    "\n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    if target.device_name != \"vta\":\n",
    "        with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "    else:\n",
    "        if env.TARGET == \"intelfocl\":\n",
    "            # multiple targets to run both on cpu and vta\n",
    "            target = {\"cpu\": env.target_vta_cpu, \"ext_dev\": target}\n",
    "        with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph1, lib1, params1 = relay.build(\n",
    "                relay_prog1, target=target, params=params1, target_host=env.target_host\n",
    "            )\n",
    "            \n",
    "#             graph2, lib2, params2 = relay.build(\n",
    "#                 relay_prog2, target=target, params=params2, target_host=env.target_host\n",
    "#             )\n",
    "#             graph3, lib3, params3 = relay.build(\n",
    "#                 relay_prog3, target=target, params=params3, target_host=env.target_host\n",
    "#             )\n",
    "#             graph4, lib4, params4 = relay.build(\n",
    "#                 relay_prog4, target=target, params=params4, target_host=env.target_host\n",
    "#             )\n",
    "            \n",
    "\n",
    "    # Measure Relay build time\n",
    "    build_time = time.time() - build_start\n",
    "    print(model + \" inference graph built in {0:.2f}s!\".format(build_time))\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = utils.tempdir()\n",
    "    lib1.export_library(temp.relpath(\"graphlib1.tar\"))\n",
    "    remote.upload(temp.relpath(\"graphlib1.tar\"))\n",
    "    lib1 = remote.load_module(\"graphlib1.tar\")\n",
    "\n",
    "#     lib2.export_library(temp.relpath(\"graphlib2.tar\"))\n",
    "#     remote.upload(temp.relpath(\"graphlib2.tar\"))\n",
    "#     lib2 = remote.load_module(\"graphlib2.tar\")\n",
    "    \n",
    "#     lib3.export_library(temp.relpath(\"graphlib3.tar\"))\n",
    "#     remote.upload(temp.relpath(\"graphlib3.tar\"))\n",
    "#     lib3 = remote.load_module(\"graphlib3.tar\")\n",
    "    \n",
    "#     lib4.export_library(temp.relpath(\"graphlib4.tar\"))\n",
    "#     remote.upload(temp.relpath(\"graphlib4.tar\"))\n",
    "#     lib4 = remote.load_module(\"graphlib4.tar\")\n",
    "\n",
    "    if env.TARGET == \"intelfocl\":\n",
    "        ctxes = [remote.ext_dev(0), remote.cpu(0)]\n",
    "        m = graph_runtime.create(graph, lib, ctxes)\n",
    "    else:\n",
    "        # Graph runtime\n",
    "        m1 = graph_runtime.create(graph1, lib1, ctx)\n",
    "#         m2 = graph_runtime.create(graph2, lib2, ctx)\n",
    "#         m3 = graph_runtime.create(graph3, lib3, ctx)\n",
    "#         m4 = graph_runtime.create(graph4, lib4, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import threading as tr\n",
    "\n",
    "#p = mp.Process(target=read_apm, args=('bob',))\n",
    "#t1 = tr.Thread(target=read_apm, args=('bob',))\n",
    "#pool = mp.Pool(4)\n",
    "# Download ImageNet categories\n",
    "categ_url = \"https://github.com/uwsampl/web-data/raw/main/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = \"https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg\"\n",
    "image_fn = \"pug.jpg\"\n",
    "#download.download(image_url, image_fn)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(image_fn).resize((224, 224))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123.0, 117.0, 104.0])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m1.set_input(**params1)\n",
    "m1.set_input(input_name, image)\n",
    "# m2.set_input(**params1)\n",
    "# m2.set_input(input_name, image)\n",
    "# m3.set_input(**params1)\n",
    "# m3.set_input(input_name, image)\n",
    "# m4.set_input(**params1)\n",
    "# m4.set_input(input_name, image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference and gather execution statistics\n",
    "# More on: :py:method:`tvm.runtime.Module.time_evaluator`\n",
    "num = 9  # number of times we run module for a single measurement\n",
    "rep = 1  # number of measurements (we derive std dev from this)\n",
    "\n",
    "\n",
    "timer = m1.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "\n",
    "\n",
    "#timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n",
    "#\n",
    "\n",
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    simulator.clear_stats()\n",
    "    timer()\n",
    "    sim_stats = simulator.stats()\n",
    "    print(\"\\nExecution statistics:\")\n",
    "    for k, v in sim_stats.items():\n",
    "        # Since we execute the workload many times, we need to normalize stats\n",
    "        # Note that there is always one warm up run\n",
    "        # Therefore we divide the overall stats by (num * rep + 1)\n",
    "        print(\"\\t{:<16}: {:>16}\".format(k, v // (num * rep + 1)))\n",
    "else:\n",
    "    #vta.init_apm(remote)\n",
    "#     vta.reset_ro_monitor(remote)\n",
    "#     vta.start_ro_monitor(remote)\n",
    "#     tcost = timer()\n",
    "#     vta.stop_ro_monitor(remote,0)\n",
    "    #vta.read_metrics(remote,0)\n",
    "    m1.run()\n",
    "    #vta.reset_apm(remote)\n",
    "    #std = np.std(tcost.results) * 1000\n",
    "    #mean = tcost.mean * 1000\n",
    "    #print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "    #print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n",
    "\n",
    "print(\"done\")\n",
    "    # Get classification results\n",
    "# tvm_output = m.get_output(0, tvm.nd.empty((env.BATCH, 1000), \"float32\", remote.cpu(0)))\n",
    "# for b in range(env.BATCH):\n",
    "#     top_categories = np.argsort(tvm_output.numpy()[b])\n",
    "#     # Report top-5 classification results\n",
    "#     print(\"\\n{} prediction for sample {}\".format(model, b))\n",
    "#     print(\"\\t#1:\", synset[top_categories[-1]])\n",
    "#     print(\"\\t#2:\", synset[top_categories[-2]])\n",
    "#     print(\"\\t#3:\", synset[top_categories[-3]])\n",
    "#     print(\"\\t#4:\", synset[top_categories[-4]])\n",
    "#     print(\"\\t#5:\", synset[top_categories[-5]])\n",
    "#     # This just checks that one of the 5 top categories\n",
    "#     # is one variety of cat; this is by no means an accurate\n",
    "#     # assessment of how quantization affects classification\n",
    "#     # accuracy but is meant to catch changes to the\n",
    "#     # quantization pass that would accuracy in the CI.\n",
    "#     cat_detected = False\n",
    "#     for k in top_categories[-5:]:\n",
    "#         if \"pug\" in synset[k]:\n",
    "#             cat_detected = True\n",
    "#     assert cat_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tvm-build-il-2] *",
   "language": "python",
   "name": "conda-env-tvm-build-il-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
