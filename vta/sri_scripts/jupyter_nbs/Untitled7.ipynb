{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb07c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srchand/anaconda3/envs/tvm-build-il-2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "import argparse, json, os, requests, sys, time\n",
    "from io import BytesIO\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "\n",
    "#from mxnet.gluon.model_zoo import vision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, utils, download\n",
    "from tvm.relay import transform\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from tvm.contrib.download import download_testdata\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.runtime.enabled(\"rpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3bf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vta.get_env()\n",
    "\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu\n",
    "\n",
    "# Dictionary lookup for when to start/end bit packing\n",
    "pack_dict = {\n",
    "    #\"resnet18_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet50\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet101\": [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"vgg16\":    [\"nn.max_pool2d\", \"nn.adaptive_avg_pool2d\"],\n",
    "    \"resnet34_v1\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet18_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet34_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet50_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "    \"resnet101_v2\": [\"nn.max_pool2d\", \"nn.global_avg_pool2d\"],\n",
    "}\n",
    "\n",
    "# Name of Gluon model to compile\n",
    "# The ``start_pack`` and ``stop_pack`` labels indicate where\n",
    "# to start and end the graph packing relay pass: in other words\n",
    "# where to start and finish offloading to VTA.\n",
    "#model = \"resnet18_v1\"\n",
    "#assert model in pack_dict\n",
    "model = \"resnet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd3a720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconfigured FPGA and RPC runtime in 0.01s!\n"
     ]
    }
   ],
   "source": [
    "remote = None\n",
    "if env.TARGET not in [\"sim\", \"tsim\", \"intelfocl\"]:\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = os.environ.get(\"TVM_TRACKER_PORT\", None)\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "    #device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "#     device_host = \"192.168.2.99\"\n",
    "    device_host=\"10.100.83.40\"\n",
    "\n",
    "    device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, int(device_port))\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(\n",
    "            env.TARGET, tracker_host, int(tracker_port), timeout=10000\n",
    "        )\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    #vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/overlays/vta_il/vta_apm_maxigp0_wrapper.bit\")\n",
    "    #vta.program_fpga(remote, bitstream=None)\n",
    "#     vta.program_fpga(remote, bitstream=\"/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/bitstreams/vta_zcu104_wrapper.bit\")\n",
    "#     vta.program_fpga(remote, bitstream=\"/mnt/hgfs/vmware_ubuntu_sf/bitstreams/vta_axi_sniffer_uart_fifo_thres_100.bit\")\n",
    "\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "    if env.TARGET in [\"intelfocl\"]:\n",
    "        # program intelfocl aocx\n",
    "        vta.program_fpga(remote, bitstream=\"vta.bitstream\")\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc6f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_exec = nn.Sequential(nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1),\n",
    "                                       padding=(1, 1)), nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d277592",
   "metadata": {},
   "outputs": [],
   "source": [
    "VTA_exec = nn.Sequential(nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1),\n",
    "                                       padding=(1, 1)), nn.ReLU(inplace=True), nn.Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1),\n",
    "                                       padding=(1, 1)), nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90509fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = nn.AdaptiveAvgPool2d((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252f8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(CPU_exec, VTA_exec, last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e596716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "schedule_log_files = glob.glob(r'/home/srchand/Desktop/research/TVM_Intel_Fork/tvm/vta/sri_scripts/logs/tuning_logs/*.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27292c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=ext_dev -keys=vta,cpu -device=vta -model=zcu104_1x16x16_i8w8a32_15_15_18_17, workload=('conv2d_nchw_spatial_pack.arm_cpu', ('TENSOR', (1, 3, 28, 28), 'float32'), ('TENSOR', (16, 3, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "/tmp/ipykernel_225999/3350765981.py:65: DeprecationWarning: legacy graph runtime behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_runtime.GraphModule for the  new recommended usage.\n",
      "  graph, lib, params = relay.build(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom model  inference graph built in 3.43s!\n"
     ]
    }
   ],
   "source": [
    "with autotvm.tophub.context(target, extra_files=schedule_log_files):\n",
    "    \n",
    "    input_name = \"input0\"\n",
    "\n",
    "    input_shape = [1, 3, 28, 28]\n",
    "    input_data = torch.randn(input_shape)\n",
    "\n",
    "    scripted_model = torch.jit.trace(model, input_data).eval()\n",
    "    shape_list = [(input_name, input_shape)]\n",
    "    \n",
    "\n",
    "    # Measure build start time\n",
    "    build_start = time.time()\n",
    "\n",
    "    # Start front end compilation\n",
    "    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "    \n",
    "    \n",
    "\n",
    "    #mod, params = relay.frontend.from_mxnet(net, shape_dict)\n",
    "    \n",
    "\n",
    "    if target.device_name == \"vta\":\n",
    "        # Perform quantization in Relay\n",
    "        # Note: We set opt_level to 3 in order to fold batch norm\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "                mod = relay.quantize.quantize(mod, params=params)\n",
    "#                 print(mod.astext(show_meta_data=False))\n",
    "#                 print(apput)\n",
    "            # Perform graph packing and constant folding for VTA target\n",
    "            assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "            # do device annotation if target is intelfocl or sim\n",
    "            relay_prog = graph_pack(\n",
    "                mod[\"main\"],\n",
    "                env.BATCH,\n",
    "                env.BLOCK_IN,\n",
    "                env.BLOCK_OUT,\n",
    "                env.WGT_WIDTH,\n",
    "                start_name='cast',\n",
    "                start_name_idx=7,\n",
    "                stop_name='nn.adaptive_avg_pool2d',\n",
    "                #start_name=\"cast\",\n",
    "                #stop_name=\"reshape\",\n",
    "                #start_name='nn.max_pool2d',\n",
    "                #stop_name='add',\n",
    "                #start_name_idx=8,\n",
    "                #stop_name_idx=227,\n",
    "                device_annot=(env.TARGET == \"intelfocl\"),\n",
    "            )\n",
    "    else:\n",
    "        relay_prog = mod[\"main\"]\n",
    "\n",
    "    # Compile Relay program with AlterOpLayout disabled\n",
    "    if target.device_name != \"vta\":\n",
    "        with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "    else:\n",
    "        if env.TARGET == \"intelfocl\":\n",
    "            # multiple targets to run both on cpu and vta\n",
    "            target = {\"cpu\": env.target_vta_cpu, \"ext_dev\": target}\n",
    "        with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "            graph, lib, params = relay.build(\n",
    "                relay_prog, target=target, params=params, target_host=env.target_host\n",
    "            )\n",
    "\n",
    "    # Measure Relay build time\n",
    "    build_time = time.time() - build_start\n",
    "    print(\"custom model \" + \" inference graph built in {0:.2f}s!\".format(build_time))\n",
    "\n",
    "    # Send the inference library over to the remote RPC server\n",
    "    temp = utils.tempdir()\n",
    "    lib.export_library(temp.relpath(\"graphlib.tar\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.tar\"))\n",
    "    lib = remote.load_module(\"graphlib.tar\")\n",
    "\n",
    "    if env.TARGET == \"intelfocl\":\n",
    "        ctxes = [remote.ext_dev(0), remote.cpu(0)]\n",
    "        m = graph_runtime.create(graph, lib, ctxes)\n",
    "    else:\n",
    "        # Graph runtime\n",
    "        m = graph_runtime.create(graph, lib, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d79659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File synset.txt exists, skip.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categ_url = \"https://github.com/uwsampl/web-data/raw/main/vta/models/\"\n",
    "categ_fn = \"synset.txt\"\n",
    "download.download(join(categ_url, categ_fn), categ_fn)\n",
    "synset = eval(open(categ_fn).read())\n",
    "\n",
    "# Download test image\n",
    "image_url = \"https://homes.cs.washington.edu/~moreau/media/vta/cat.jpg\"\n",
    "image_fn = \"pug.jpg\"\n",
    "#download.download(image_url, image_fn)\n",
    "\n",
    "# Prepare test image for inference\n",
    "image = Image.open(image_fn).resize((28, 28))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = np.array(image) - np.array([123.0, 117.0, 104.0])\n",
    "image /= np.array([58.395, 57.12, 57.375])\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = image[np.newaxis, :]\n",
    "image = np.repeat(image, env.BATCH, axis=0)\n",
    "\n",
    "# Set the network parameters and inputs\n",
    "m.set_input(**params)\n",
    "m.set_input(input_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e30dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161e98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tvm-build-il-2] *",
   "language": "python",
   "name": "conda-env-tvm-build-il-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
